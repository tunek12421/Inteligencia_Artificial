{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a647491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EJERCICIO 3: PROCESAMIENTO DE DATOS DE TEXTO - FAKE NEWS ===\n",
      "\n",
      "PUNTO 1: Cargando archivos Fake.csv y True.csv como DataFrames distintos:\n",
      "======================================================================\n",
      "Archivo 'fake.csv' cargado exitosamente\n",
      "Noticias falsas: 23,481 registros × 4 columnas\n",
      "Columnas en fake.csv: ['title', 'text', 'subject', 'date']\n",
      "Archivo 'True.csv' cargado exitosamente\n",
      "Noticias verdaderas: 21,417 registros × 4 columnas\n",
      "Columnas en True.csv: ['title', 'text', 'subject', 'date']\n",
      "\n",
      "Muestra de noticias falsas (primeras 3 filas):\n",
      "                                               title  \\\n",
      "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
      "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
      "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
      "\n",
      "                                                text subject  \\\n",
      "0  Donald Trump just couldn t wish all Americans ...    News   \n",
      "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
      "2  On Friday, it was revealed that former Milwauk...    News   \n",
      "\n",
      "                date  \n",
      "0  December 31, 2017  \n",
      "1  December 31, 2017  \n",
      "2  December 30, 2017  \n",
      "\n",
      "Muestra de noticias verdaderas (primeras 3 filas):\n",
      "                                               title  \\\n",
      "0  As U.S. budget fight looms, Republicans flip t...   \n",
      "1  U.S. military to accept transgender recruits o...   \n",
      "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
      "\n",
      "                                                text       subject  \\\n",
      "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
      "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
      "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
      "\n",
      "                 date  \n",
      "0  December 31, 2017   \n",
      "1  December 29, 2017   \n",
      "2  December 31, 2017   \n",
      "\n",
      "PUNTO 2: Agregando columna 'label':\n",
      "===================================\n",
      "Etiqueta agregada a noticias falsas: label = 0\n",
      "Etiqueta agregada a noticias verdaderas: label = 1\n",
      "\n",
      "Verificación de etiquetas:\n",
      "Noticias falsas con label=0: 23,481\n",
      "Noticias verdaderas con label=1: 21,417\n",
      "\n",
      "Columnas después de agregar label:\n",
      "fake.csv: ['title', 'text', 'subject', 'date', 'label']\n",
      "true.csv: ['title', 'text', 'subject', 'date', 'label']\n",
      "\n",
      "PUNTO 3: Uniendo ambos DataFrames en uno solo:\n",
      "=============================================\n",
      "DataFrames combinados exitosamente\n",
      "Total de registros: 44,898\n",
      "Total de columnas: 5\n",
      "Columnas en dataset combinado: ['title', 'text', 'subject', 'date', 'label']\n",
      "\n",
      "Distribución final de etiquetas:\n",
      "Noticias falsas (0): 23,481 (52.3%)\n",
      "Noticias verdaderas (1): 21,417 (47.7%)\n",
      "\n",
      "PUNTO 4: Eliminando columnas subject y date, dejando solo text y label:\n",
      "===========================================================================\n",
      "Columnas antes de eliminar: ['title', 'text', 'subject', 'date', 'label']\n",
      "Columna 'subject' encontrada - será eliminada\n",
      "Columna 'date' encontrada - será eliminada\n",
      "Columnas eliminadas: ['subject', 'date']\n",
      "Dataset final con columnas deseadas: ['text', 'label']\n",
      "Columnas finales: ['text', 'label']\n",
      "Tamaño final: 44,898 filas × 2 columnas\n",
      "\n",
      "PUNTO 5: Verificando valores nulos:\n",
      "===================================\n",
      "Valores nulos por columna:\n",
      "  text: Sin valores nulos\n",
      "  label: Sin valores nulos\n",
      "\n",
      "No se encontraron valores nulos - dataset está completo\n",
      "\n",
      "PUNTO 6: Guardando dataset como noticias_procesadas.csv:\n",
      "=======================================================\n",
      "Dataset guardado exitosamente como 'noticias_procesadas.csv'\n",
      "Ubicación: directorio actual\n",
      "Tamaño del archivo: 44,898 filas × 2 columnas\n",
      "\n",
      "Información del archivo guardado:\n",
      "Nombre: noticias_procesadas.csv\n",
      "Columnas: ['text', 'label']\n",
      "Registros totales: 44,898\n",
      "Distribución final:\n",
      "  Noticias falsas (0): 23,481\n",
      "  Noticias verdaderas (1): 21,417\n",
      "\n",
      "Muestra del dataset procesado final:\n",
      "========================================\n",
      "Noticia 1 (FALSA):\n",
      "  Donald Trump just couldn t wish all Americans a Happy New Year and leave it at that. Instead, he had...\n",
      "\n",
      "Noticia 2 (FALSA):\n",
      "  House Intelligence Committee Chairman Devin Nunes is going to have a bad day. He s been under the as...\n",
      "\n",
      "Noticia 3 (FALSA):\n",
      "  On Friday, it was revealed that former Milwaukee Sheriff David Clarke, who was being considered for ...\n",
      "\n",
      "\n",
      "RESUMEN DEL PROCESAMIENTO REALIZADO:\n",
      "========================================\n",
      "• Archivos originales procesados: fake.csv y true.csv\n",
      "• Dataset final: 44,898 noticias etiquetadas\n",
      "• Formato final: texto + etiqueta binaria\n",
      "• Archivo generado: noticias_procesadas.csv\n",
      "• Dataset listo para análisis de texto o machine learning\n",
      "\n",
      "EJERCICIO 3 COMPLETADO EXITOSAMENTE!\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# EJERCICIO 3: Carga y preparación de datos de texto con el dataset \"Fake News\"\n",
    "# Dataset: Fake.csv y True.csv\n",
    "# Objetivo: Cumplir exactamente los 6 puntos del enunciado\n",
    "# ==============================================\n",
    "\n",
    "# Paso 1: Importar bibliotecas necesarias\n",
    "import pandas as pd # Para manejo de datos en forma de tablas\n",
    "import numpy as np # Para operaciones numéricas\n",
    "\n",
    "print(\"=== EJERCICIO 3: PROCESAMIENTO DE DATOS DE TEXTO - FAKE NEWS ===\\n\")\n",
    "\n",
    "# PUNTO 1: Carga ambos archivos como dos DataFrames distintos\n",
    "print(\"PUNTO 1: Cargando archivos Fake.csv y True.csv como DataFrames distintos:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Cargar archivo de noticias falsas\n",
    "try:\n",
    "    df_fake = pd.read_csv(\"../../Dataset/fake.csv\")\n",
    "    print(\"Archivo 'fake.csv' cargado exitosamente\")\n",
    "    print(f\"Noticias falsas: {df_fake.shape[0]:,} registros × {df_fake.shape[1]} columnas\")\n",
    "    print(f\"Columnas en fake.csv: {list(df_fake.columns)}\")\n",
    "except FileNotFoundError:\n",
    "    try:\n",
    "        # Intentar con nombre en mayúscula\n",
    "        df_fake = pd.read_csv(\"../../Dataset/Fake.csv\")\n",
    "        print(\"Archivo 'Fake.csv' cargado exitosamente\")\n",
    "        print(f\"Noticias falsas: {df_fake.shape[0]:,} registros × {df_fake.shape[1]} columnas\")\n",
    "        print(f\"Columnas en Fake.csv: {list(df_fake.columns)}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: No se encontró el archivo fake.csv o Fake.csv\")\n",
    "        print(\"Asegúrate de que el archivo esté en la carpeta Dataset/\")\n",
    "        exit()\n",
    "\n",
    "# Cargar archivo de noticias verdaderas\n",
    "try:\n",
    "    df_true = pd.read_csv(\"../../Dataset/true.csv\")\n",
    "    print(\"Archivo 'true.csv' cargado exitosamente\")\n",
    "    print(f\"Noticias verdaderas: {df_true.shape[0]:,} registros × {df_true.shape[1]} columnas\")\n",
    "    print(f\"Columnas en true.csv: {list(df_true.columns)}\")\n",
    "except FileNotFoundError:\n",
    "    try:\n",
    "        # Intentar con nombre en mayúscula\n",
    "        df_true = pd.read_csv(\"../../Dataset/True.csv\")\n",
    "        print(\"Archivo 'True.csv' cargado exitosamente\")\n",
    "        print(f\"Noticias verdaderas: {df_true.shape[0]:,} registros × {df_true.shape[1]} columnas\")\n",
    "        print(f\"Columnas en True.csv: {list(df_true.columns)}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: No se encontró el archivo true.csv o True.csv\")\n",
    "        print(\"Asegúrate de que el archivo esté en la carpeta Dataset/\")\n",
    "        exit()\n",
    "\n",
    "# Mostrar muestra de ambos DataFrames\n",
    "print(f\"\\nMuestra de noticias falsas (primeras 3 filas):\")\n",
    "print(df_fake.head(3))\n",
    "\n",
    "print(f\"\\nMuestra de noticias verdaderas (primeras 3 filas):\")\n",
    "print(df_true.head(3))\n",
    "\n",
    "# PUNTO 2: Agrega una columna label con valor 0 para noticias falsas y 1 para verdaderas\n",
    "print(f\"\\nPUNTO 2: Agregando columna 'label':\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Crear copias para evitar modificar los originales\n",
    "df_fake_labeled = df_fake.copy()\n",
    "df_true_labeled = df_true.copy()\n",
    "\n",
    "# Agregar columna label\n",
    "df_fake_labeled['label'] = 0  # 0 = Noticia falsa\n",
    "df_true_labeled['label'] = 1  # 1 = Noticia verdadera\n",
    "\n",
    "print(f\"Etiqueta agregada a noticias falsas: label = 0\")\n",
    "print(f\"Etiqueta agregada a noticias verdaderas: label = 1\")\n",
    "\n",
    "# Verificar las etiquetas\n",
    "print(f\"\\nVerificación de etiquetas:\")\n",
    "print(f\"Noticias falsas con label=0: {(df_fake_labeled['label'] == 0).sum():,}\")\n",
    "print(f\"Noticias verdaderas con label=1: {(df_true_labeled['label'] == 1).sum():,}\")\n",
    "\n",
    "print(f\"\\nColumnas después de agregar label:\")\n",
    "print(f\"fake.csv: {list(df_fake_labeled.columns)}\")\n",
    "print(f\"true.csv: {list(df_true_labeled.columns)}\")\n",
    "\n",
    "# PUNTO 3: Une ambos DataFrames en uno solo\n",
    "print(f\"\\nPUNTO 3: Uniendo ambos DataFrames en uno solo:\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Concatenar los DataFrames\n",
    "df_combined = pd.concat([df_fake_labeled, df_true_labeled], ignore_index=True)\n",
    "\n",
    "print(f\"DataFrames combinados exitosamente\")\n",
    "print(f\"Total de registros: {df_combined.shape[0]:,}\")\n",
    "print(f\"Total de columnas: {df_combined.shape[1]}\")\n",
    "print(f\"Columnas en dataset combinado: {list(df_combined.columns)}\")\n",
    "\n",
    "# Verificar la distribución de etiquetas\n",
    "distribucion_labels = df_combined['label'].value_counts().sort_index()\n",
    "print(f\"\\nDistribución final de etiquetas:\")\n",
    "print(f\"Noticias falsas (0): {distribucion_labels[0]:,} ({distribucion_labels[0]/len(df_combined)*100:.1f}%)\")\n",
    "print(f\"Noticias verdaderas (1): {distribucion_labels[1]:,} ({distribucion_labels[1]/len(df_combined)*100:.1f}%)\")\n",
    "\n",
    "# PUNTO 4: Elimina las columnas subject y date, dejando solo text y label\n",
    "print(f\"\\nPUNTO 4: Eliminando columnas subject y date, dejando solo text y label:\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "print(f\"Columnas antes de eliminar: {list(df_combined.columns)}\")\n",
    "\n",
    "# Verificar qué columnas existen antes de eliminar\n",
    "columnas_a_eliminar = []\n",
    "if 'subject' in df_combined.columns:\n",
    "    columnas_a_eliminar.append('subject')\n",
    "    print(f\"Columna 'subject' encontrada - será eliminada\")\n",
    "if 'date' in df_combined.columns:\n",
    "    columnas_a_eliminar.append('date')\n",
    "    print(f\"Columna 'date' encontrada - será eliminada\")\n",
    "\n",
    "# Eliminar columnas especificadas\n",
    "if columnas_a_eliminar:\n",
    "    df_processed = df_combined.drop(columns=columnas_a_eliminar)\n",
    "    print(f\"Columnas eliminadas: {columnas_a_eliminar}\")\n",
    "else:\n",
    "    df_processed = df_combined.copy()\n",
    "    print(f\"No se encontraron las columnas 'subject' o 'date'\")\n",
    "\n",
    "# Verificar si existen las columnas text y label\n",
    "columnas_deseadas = ['text', 'label']\n",
    "columnas_disponibles = [col for col in columnas_deseadas if col in df_processed.columns]\n",
    "\n",
    "if len(columnas_disponibles) == 2:\n",
    "    df_final = df_processed[columnas_deseadas].copy()\n",
    "    print(f\"Dataset final con columnas deseadas: {list(df_final.columns)}\")\n",
    "else:\n",
    "    print(f\"Advertencia: No se encontraron todas las columnas esperadas\")\n",
    "    print(f\"Columnas disponibles: {list(df_processed.columns)}\")\n",
    "    \n",
    "    # Adaptar a las columnas que existan\n",
    "    if 'title' in df_processed.columns and 'text' not in df_processed.columns:\n",
    "        df_final = df_processed[['title', 'label']].copy()\n",
    "        df_final = df_final.rename(columns={'title': 'text'})\n",
    "        print(f\"Usando 'title' como 'text'\")\n",
    "    elif len(df_processed.columns) >= 2:\n",
    "        # Tomar las últimas dos columnas (asumiendo que una es text-like y otra es label)\n",
    "        text_col = [col for col in df_processed.columns if col != 'label'][0]\n",
    "        df_final = df_processed[[text_col, 'label']].copy()\n",
    "        if text_col != 'text':\n",
    "            df_final = df_final.rename(columns={text_col: 'text'})\n",
    "        print(f\"Usando '{text_col}' como 'text'\")\n",
    "    else:\n",
    "        df_final = df_processed.copy()\n",
    "\n",
    "print(f\"Columnas finales: {list(df_final.columns)}\")\n",
    "print(f\"Tamaño final: {df_final.shape[0]:,} filas × {df_final.shape[1]} columnas\")\n",
    "\n",
    "# PUNTO 5: Verifica si hay valores nulos\n",
    "print(f\"\\nPUNTO 5: Verificando valores nulos:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "valores_nulos = df_final.isnull().sum()\n",
    "print(f\"Valores nulos por columna:\")\n",
    "total_nulos = 0\n",
    "for columna, nulos in valores_nulos.items():\n",
    "    if nulos > 0:\n",
    "        porcentaje = (nulos / len(df_final)) * 100\n",
    "        print(f\"  {columna}: {nulos:,} valores nulos ({porcentaje:.2f}%)\")\n",
    "        total_nulos += nulos\n",
    "    else:\n",
    "        print(f\"  {columna}: Sin valores nulos\")\n",
    "\n",
    "if total_nulos > 0:\n",
    "    print(f\"\\nTotal de valores nulos encontrados: {total_nulos:,}\")\n",
    "    print(\"Eliminando filas con valores nulos...\")\n",
    "    filas_antes = len(df_final)\n",
    "    df_final = df_final.dropna()\n",
    "    filas_despues = len(df_final)\n",
    "    print(f\"Filas eliminadas: {filas_antes - filas_despues:,}\")\n",
    "    print(f\"Filas restantes: {filas_despues:,}\")\n",
    "else:\n",
    "    print(f\"\\nNo se encontraron valores nulos - dataset está completo\")\n",
    "\n",
    "# PUNTO 6: Guarda el nuevo dataset como noticias_procesadas.csv\n",
    "print(f\"\\nPUNTO 6: Guardando dataset como noticias_procesadas.csv:\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "archivo_salida = \"noticias_procesadas.csv\"\n",
    "try:\n",
    "    df_final.to_csv(archivo_salida, index=False)\n",
    "    print(f\"Dataset guardado exitosamente como '{archivo_salida}'\")\n",
    "    print(f\"Ubicación: directorio actual\")\n",
    "    print(f\"Tamaño del archivo: {len(df_final):,} filas × {len(df_final.columns)} columnas\")\n",
    "    \n",
    "    # Información del archivo guardado\n",
    "    print(f\"\\nInformación del archivo guardado:\")\n",
    "    print(f\"Nombre: {archivo_salida}\")\n",
    "    print(f\"Columnas: {list(df_final.columns)}\")\n",
    "    print(f\"Registros totales: {len(df_final):,}\")\n",
    "    \n",
    "    if 'label' in df_final.columns:\n",
    "        dist_final = df_final['label'].value_counts().sort_index()\n",
    "        print(f\"Distribución final:\")\n",
    "        print(f\"  Noticias falsas (0): {dist_final[0]:,}\")\n",
    "        print(f\"  Noticias verdaderas (1): {dist_final[1]:,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error al guardar el archivo: {e}\")\n",
    "\n",
    "# Mostrar muestra del dataset final\n",
    "print(f\"\\nMuestra del dataset procesado final:\")\n",
    "print(\"=\" * 40)\n",
    "for i, row in df_final.head(3).iterrows():\n",
    "    texto_col = 'text' if 'text' in df_final.columns else df_final.columns[0]\n",
    "    label_val = \"VERDADERA\" if row['label'] == 1 else \"FALSA\"\n",
    "    print(f\"Noticia {i+1} ({label_val}):\")\n",
    "    print(f\"  {row[texto_col][:100]}...\")\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "# Resumen del procesamiento realizado\n",
    "print(f\"\\nRESUMEN DEL PROCESAMIENTO REALIZADO:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"• Archivos originales procesados: fake.csv y true.csv\")\n",
    "print(f\"• Dataset final: {len(df_final):,} noticias etiquetadas\")\n",
    "print(f\"• Formato final: texto + etiqueta binaria\")\n",
    "print(f\"• Archivo generado: {archivo_salida}\")\n",
    "print(f\"• Dataset listo para análisis de texto o machine learning\")\n",
    "\n",
    "print(f\"\\nEJERCICIO 3 COMPLETADO EXITOSAMENTE!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
